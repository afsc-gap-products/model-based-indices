---
title: "sdmTMB Bering indices"
output:
  bookdown::pdf_document2:
    highlight: pygments
    toc: true
    number_sections: true
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 7,
  fig.asp = 0.618,
  cache = FALSE,
  autodep = TRUE,
  cache.comments = FALSE
)
```

```{r packages, message=FALSE, warning=FALSE, cache=FALSE}
#pak::pak("pbs-assess/sdmTMB")
#pak::pak("pbs-assess/sdmTMB@index-split")
#pak::pak("afsc-gap-products/coldpool")
library(sdmTMB)
library(dplyr)
library(ggplot2)
library(here)

species <- "yellowfin_sole" 
#pollock pacific_cod yellowfin_sole
```

We will fit geostatistical spatiotemporal models with sdmTMB for the purposes of index standardization. We will use data from the EBS/NBS AFSC GAP bottom trawl surveys. The density units we will work in are either kg/km^2^ or n/km^2^, for biomass or numerical abundance. 

```{r data, echo = TRUE}
# TODO: standardize names better
if(species == "pacific_cod"){
  dat_ll <- readRDS(here("species_specific_code", "BS", species, "production", 
                        "data", "data_geostat_numerical_index.RDS"))
  dat_ll <-  dplyr::transmute(dat_ll,
                         cpue = Catch_N / AreaSwept_km2, #note last cod model used catch ~ effort
                         year = as.integer(Year),
                         vessel = "missing",
                         effort = 1, # area swept is 1 when using CPUE instead of observed weight
                         lat = Lat,
                         lon = Lon,
                         pass = 0) %>% 
                as.data.frame() # ensure not a tibble
}
if(species == "pollock"){
  dat_ll <- read.csv(here("species_specific_code", "BS", species, "VAST_ddc_all_2023.csv"))  
  dat_ll <-  dplyr::transmute(dat_ll,
                         cpue = ddc_cpue_kg_ha * 100, # converts cpue from kg/ha to kg/km^2
                         year = as.integer(year),
                         vessel = "missing",
                         effort = 1, # area swept is 1 when using CPUE instead of observed weight
                         lat = start_latitude,
                         lon = start_longitude,
                         pass = 0) %>% 
                as.data.frame() # ensure not a tibble
}
if(species == "yellowfin_sole"){
  dat_ll <- readRDS(here("species_specific_code", "BS", species, "production", 
                       "data", "data_geostat_biomass_index.RDS"))  
  dat_ll <-  dplyr::transmute(dat_ll,
                         cpue = Catch_KG / AreaSwept_km2,
                         year = as.integer(Year),
                         vessel = "missing",
                         effort = 1, # area swept is 1 when using CPUE instead of observed weight
                         lat = Lat,
                         lon = Lon,
                         pass = 0) %>% 
                as.data.frame() # ensure not a tibble
}
```

We also need to pull in the appropriate environmental covariate as this is used as a spatially varying covariate in AFSC GAP Bering Sea indices. For yellowfin sole, this is the mean bottom temperature in waters less than 100m. For other species, this is the cold pool extent. The cold pool is defined here as the areal extent (in km^2^) of seawater equal to or colder than 2 degrees Celsius near the seafloor, calculated from observations from the AFSC GAP EBS/NBS bottom trawl survey. We center and scale this for inclusion as a covariate.

```{r covariate, echo = TRUE}
if(species == "yellowfin_sole"){
  env <- scale(coldpool:::cold_pool_index$MEAN_BT_LT100M)
} else {
  env <- scale(coldpool:::cold_pool_index$AREA_LTE2_KM2)
}

dat_ll <- left_join(dat_ll, env, by = "year") 
```
Now we fit the model in sdmTMB:

```{r sdmTMB-example, echo = TRUE}
dat <- dat_ll %>% 
  rename(X = lon, Y = lat)
dat$year_f <- as.factor(dat$year)

# detect if any years have occurrences at every haul and fix params as needed
mins <- dat %>% group_by(year) %>% summarize(min = min(cpue))
if(sum(mins$min) == 0){
  control = sdmTMBcontrol()
} else {
  no_zero_yr <- as.integer(mins %>% filter(min > 0) %>% select(year))
			# set up map and fix value of p(occurrence) to slightly less than 1:
			yrs <- unique(dat$year)
			.map <- seq_along(yrs)
			.map[yrs %in% no_zero_yr] <- NA
			.map <- factor(.map)
			.start <- rep(0, length(yrs))
			.start[yrs %in% no_zero_yr] <- 20

			control =  sdmTMBcontrol(
			      map = list(b_j = .map),
			      start = list(b_j = .start)
			    )
}

#project coordinates (could also use add_utm_columns())
coordinates(dat) <- ~ X + Y
proj4string(dat) <- CRS("+proj=longlat +datum=WGS84")
dat <- as.data.frame(spTransform(dat, CRS("+proj=utm +zone=2")))
# scale to km so values don't get too large
dat$X <- dat$coords.x1 / 1000
dat$Y <- dat$coords.x2 / 1000

f1 <- here("species_specific_code", "BS", species, "index_comparison", "fit_sdmTMB.RDS")
if (!file.exists(f1)) {
  # make mesh and fit model
  mesh <-  make_mesh(dat, xy_cols = c("X", "Y"), mesh = fit$spatial_list$MeshList$anisotropic_mesh) 
  #mesh <-  make_mesh(dat, xy_cols = c("X", "Y"), n_knots = 50, type = "kmeans") #coarser mesh for experimentation
  
  fit_sdmTMB <- sdmTMB( 
    cpue ~ 0 + year_f,
    spatial_varying = ~ env,
    data = dat, 
    mesh = mesh,
    family = delta_gamma(type = "poisson-link"), 
    time = "year", 
    spatial = "on",
    spatiotemporal = "ar1",
    extra_time = 2020L, 
    silent = FALSE,
    anisotropy = TRUE,
    control = control,
    do_fit = TRUE
  )
  fit_sdmTMB
  saveRDS(fit_sdmTMB, file = here("species_specific_code", "BS", species, "index_comparison", "fit_sdmTMB.RDS"))
} else {
  fit_sdmTMB <- readRDS(f1)
}

# diagnose estimation issues due to model structure
#TMBhelper::check_estimability(fit_sdmTMB$tmb_obj)
```

We can compare the index we would get using sdmTMB. 

```{r sdmTMB-index, echo=TRUE}
#TODO: Scrap below and instead upload saved prediction grid

# prep prediction grids (all, EBS, NBS) and transform to UTM projection
load(here("extrapolation_grids", "eastern_bering_sea_grid.rda"))
load(here("extrapolation_grids", "northern_bering_sea_grid.rda"))

# EBS grid
grid_ll_ebs <- as.data.frame(eastern_bering_sea_grid)
names(grid_ll_ebs) <- tolower(names(grid_ll_ebs))
grid_ll_ebs <- grid_ll_ebs %>% 
  rename(X = lon, Y = lat)
coordinates(grid_ll_ebs) <- ~ X + Y
proj4string(grid_ll_ebs) <- CRS("+proj=longlat +datum=WGS84")
grid_ebs <- as.data.frame(spTransform(grid_ll_ebs, CRS("+proj=utm +zone=2")))
grid_ebs$X <- grid_ebs$coords.x1 / 1000 # scale to km to work with smaller numbers
grid_ebs$Y <- grid_ebs$coords.x2 / 1000 

# NBS grid
grid_ll_nbs <- as.data.frame(northern_bering_sea_grid)
names(grid_ll_nbs) <- tolower(names(grid_ll_nbs))
grid_ll_nbs <- grid_ll_nbs %>% 
  rename(X = lon, Y = lat)
coordinates(grid_ll_nbs) <- ~ X + Y
proj4string(grid_ll_nbs) <- CRS("+proj=longlat +datum=WGS84")
grid_nbs <- as.data.frame(spTransform(grid_ll_nbs, CRS("+proj=utm +zone=2")))
grid_nbs$X <- grid_nbs$coords.x1 / 1000 # scale to km to work with smaller numbers
grid_nbs$Y <- grid_nbs$coords.x2 / 1000 

# Combined grid
grid <- bind_rows(grid_nbs, grid_ebs)

# replicate extrapolation grids for each year in data
pred_grid_ebs <- replicate_df(grid_ebs, "year_f", unique(dat$year_f))
pred_grid_nbs <- replicate_df(grid_nbs, "year_f", unique(dat$year_f))
pred_grid <- replicate_df(grid, "year_f", unique(dat$year_f))
pred_grid_ebs$year <- as.integer(as.character(factor(pred_grid_ebs$year_f)))
pred_grid_nbs$year <- as.integer(as.character(factor(pred_grid_nbs$year_f)))
pred_grid$year <- as.integer(as.character(factor(pred_grid$year_f)))

# join in environmental covariate (cold pool or mean bottom temperature)
pred_grid_ebs <- left_join(pred_grid_ebs, rename(env_join, cpe = env), by = "year") 
pred_grid_nbs <- left_join(pred_grid_nbs, rename(env_join, cpe = env), by = "year")
pred_grid <- left_join(pred_grid, rename(env_join, cpe = env), by = "year")

# get predictions for total area, and the two subareas of interest (EBS, NBS)
# f2 <- here("species_specific_code", "BS", species,
#            "index_comparison", "predictions.RData")
# if (!file.exists(f2)) {
#   p <- predict(fit_sdmTMB, newdata = pred_grid, return_tmb_object = TRUE)
#   p_ebs <- predict(fit_sdmTMB, newdata = pred_grid_ebs, return_tmb_object = TRUE)
#   p_nbs <- predict(fit_sdmTMB, newdata = pred_grid_nbs, return_tmb_object = TRUE)
#     save(p, p_ebs, p_nbs, file = f2)
# } else {
#   load(f2)
# }

# get indices for total area, and the two subareas of interest (EBS, NBS)
# f3 <- here("species_specific_code", "BS", species, 
#            "index_comparison", "indices.RData")
# if (!file.exists(f3)) {
#   gc()
#   ind <- get_index(p, bias_correct = FALSE, area = pred_grid$area_in_survey_km2)
#   ind$stratum <- "Both"
# 
#   ind_ebs <- get_index(p_ebs, bias_correct = FALSE, area = pred_grid_ebs$area_in_survey_km2)
#   ind_ebs$stratum <- "EBS"
# 
#   ind_nbs <- get_index(p_nbs, bias_correct = FALSE, area = pred_grid_nbs$area_in_survey_km2)
#   ind_nbs$stratum <- "NBS"
#   save(ind, ind_ebs, ind_nbs, file = f3)
# } else {
# load(f3)
# }

# NOTE: if using get_index_split() rather than get_index() you need to pass the 
# model object and new data (not prediction object, you can bypass that step) and run:
f3 <- here("species_specific_code", "BS", species,
           "index_comparison", "indices.RData")
if (!file.exists(f3)) {
  gc()
  ind <- get_index_split(fit_sdmTMB, newdata = pred_grid, nsplit = 2, # may need 6 if have 64GB RAM
                         bias_correct = TRUE, area = pred_grid$area_in_survey_km2)
  #if using offsets also include the argument predict_args = list(offset = fake_offset)
  ind$stratum <- "Both"

  ind_ebs <- get_index_split(fit_sdmTMB, newdata = pred_grid_ebs, nsplit = 2,
                             bias_correct = TRUE, area = pred_grid_ebs$area_in_survey_km2)
  ind_ebs$stratum <- "EBS"

  ind_nbs <- get_index_split(fit_sdmTMB, newdata = pred_grid_nbs, nsplit = 2,
                             bias_correct = TRUE, area = pred_grid_nbs$area_in_survey_km2)
  ind_nbs$stratum <- "NBS"
  save(ind, ind_ebs, ind_nbs, file = here("species_specific_code", "BS", species, "index_comparison", "indices.RData"))
} else {
load(f3)
}
```

Now, we can compare the index to the prior model.

```{r index-compare, message=FALSE, warning=FALSE}
vast_i <- read.csv(here("species_specific_code", "BS", species, "index_comparison", "Index.csv")) %>%
  mutate(index = "VAST", year = as.numeric(Time), est = Estimate, 
    se = Std..Error.for.ln.Estimate.) %>% 
  select(index, year, est, se, stratum = Stratum) %>% 
  filter(year != 2020) %>%
  mutate(lwr = exp(log(est) + qnorm(0.025) * se)) %>% 
  mutate(upr = exp(log(est) + qnorm(0.975) * se))
sdm_i <- bind_rows(ind, ind_ebs, ind_nbs) %>% mutate(index = "sdmTMB")
both_i <- bind_rows(sdm_i, vast_i) %>% filter(est > 0)

ggplot(filter(both_i, stratum == "Both"), aes(x = year, y = est, ymin = lwr, ymax = upr, colour = index)) + 
  geom_ribbon(alpha = 0.1) +
  geom_line(alpha = 0.8) + 
  ylim(0, max(both_i$upr)) +
  ggtitle("EBS + NBS") +
  coord_cartesian(expand = FALSE)

ggplot(filter(both_i, stratum == "EBS"), aes(x = year, y = est, ymin = lwr, ymax = upr, colour = index)) + 
  geom_ribbon(alpha = 0.1) +
  geom_line(alpha = 0.8) + 
  ggtitle("EBS") +
  coord_cartesian(expand = FALSE)

ggplot(filter(both_i, stratum == "NBS"), aes(x = year, y = est, ymin = lwr, ymax = upr, colour = index)) + 
  geom_ribbon(alpha = 0.1) +
  geom_line(alpha = 0.8) + 
  ggtitle("NBS") +
  coord_cartesian(expand = FALSE)
```

This document was built using:

```{r, echo=TRUE}
R.Version()$version.string
packageVersion("VAST")
packageVersion("FishStatsUtils")
```