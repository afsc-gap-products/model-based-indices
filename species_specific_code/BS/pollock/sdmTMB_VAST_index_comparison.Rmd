
---
title: "Comparing VAST and sdmTMB pollock indices"
output:
  bookdown::pdf_document2:
    highlight: pygments
    toc: true
    number_sections: true
---

```{r setup, include = FALSE, cache=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 7,
  fig.asp = 0.618,
  cache = TRUE,
  autodep = TRUE,
  cache.comments = FALSE
)
```

```{r packages, message=FALSE, warning=FALSE, cache=FALSE}
library(TMB)
library(VAST)
library(sp)
library(sdmTMB)
library(coldpool)
library(here)
```

We will fit geostatistical spatiotemporal models with VAST and sdmTMB for the purposes of index standardization and compare the outputs given the same data. We will use pollock data from the EBS/NBS AFSC GAP bottom trawl surveys. The density units are converted from kg/ha to kg/km^2^. 

```{r data, echo = TRUE}
dat_ll <- read.csv(here("species_specific_code", "BS", "pollock", "VAST_ddc_all_2023.csv"))

dat_ll <-  dplyr::transmute(dat_ll,
                         cpue_kg_km2 = ddc_cpue_kg_ha * 100, # converts cpue from kg/ha to kg/km^2
                         year = year,
                         vessel = "missing",
                         effort = 1, # area swept is 1 when using CPUE instead of observed weight
                         lat = start_latitude,
                         lon = start_longitude,
                         pass = 0) %>% 
                as.data.frame() # ensure not a tibble

# create output directory for VAST results
# workDir <- 
# dir.create(workDir, showWarnings = FALSE)
```

We also need to pull in the cold pool extent, as that is used as a spatially varying covariate in AFSC GAP Bering Sea shelf indices. The cold pool is defined here as the areal extent (in km^2^) of seawater equal to or colder than 2 degrees Celsius near the seafloor, calculated from observations from the AFSC GAP EBS/NBS bottom trawl survey. We center and scale this for inclusion as a covariate.

```{r coldpool, echo = TRUE}
cpe <- scale(coldpool:::cold_pool_index$AREA_LTE2_KM2)

covariate_data <- data.frame(year = c(coldpool:::cold_pool_index$YEAR, 2020),
                             lat = mean(dat_ll$lat),
                             lon = mean(dat_ll$lon), 
                             cpe = c(cpe, 0))

dat_ll <- left_join(dat_ll, select(covariate_data, year, cpe), by = "year")
```

We begin by specifying the VAST model. To specify the mesh used to approximate the spatial process, which is used in the SPDE calculations, we use the k-means method in VAST. Rather than specifying the cutoff distance, meshes in VAST are typically generated by specifying only the number of knots, which we will later pass, along with other model settings to the function make_settings. We will use 750 knots, the same number in the mesh created in the existing production VAST index for this stock and region.

We will include a factor predictor that represents the mean estimate for each time slice. Settings used for index standardization are specified partially by specifying `purpose = "index2"` but we also explicitly provide arguments for these and other key settings here. 
 
```{r config, echo = TRUE}
FieldConfig <- c("Omega1"="IID", "Epsilon1"="IID", "Omega2"="IID", "Epsilon2"="IID")
RhoConfig <- c("Beta1" = 0, "Beta2" = 0, "Epsilon1" = 4, "Epsilon2" = 4)
OverdispersionConfig <- c("Eta1"=0, "Eta2"=0)
```

Unlike in sdmTMB, the fitting and predicting steps are all accomplished with the function `fit_model()` and thus we need to specify the prediction grid (referred to as the "extrapolation grid" in VAST). Here, X and Y are coordinates in UTM zone 3.

```{r settings, echo = TRUE}
settings <- make_settings(
  n_x = 750, # number of vertices in the SPDE mesh
  Region = c("Eastern_Bering_Sea", "Northern_Bering_Sea"),
  purpose = "index2", # index of abundance with Gamma for positive catches
  fine_scale = TRUE, # use bilinear interpolation from the INLA 'A' matrix
  zone = 3,
  FieldConfig = FieldConfig,
  RhoConfig = RhoConfig,
  OverdispersionConfig = c("Eta1" = 0, "Eta2" = 0),
  Options = c("Calculate_Range" = TRUE, "Calculate_effective_area" = TRUE, 
              "treat_nonencounter_as_zero" = FALSE),
  ObsModel = c(2, 1), # conventional logit-linked delta-Gamma; (2,4) if there are years with 100% encounter rate; (10, 2) for Tweedie
  bias.correct = TRUE,
  use_anisotropy = TRUE,
  max_cells = Inf, # use all grid cells from the extrapolation grid, production model used 2000
  knot_method = "grid", # or "samples"
  strata.limits = data.frame(STRATA = as.factor('All_areas'))
)
```

Next we will fit a GLMM (generalized linear mixed effects model).

```{r fit, echo = TRUE, results = 'hide'}
 # create folder for saved output:
dir.create(paste0(here("doc", "appendix-VAST-pg")), showWarnings = FALSE)

f <- here("doc", "appendix-VAST-pg", "vast-cache.rds")
if (!file.exists(f)) {
  tictoc::tic()
  fit <- fit_model(
    settings = settings,
    Lat_i = dat_ll[, "lat"],
    Lon_i = dat_ll[, "lon"],
    t_i = dat_ll[, "year"],
    b_i = dat_ll[, "cpue_kg_km2"],
    a_i = dat_ll[, "effort"],
    create_strata_per_region = TRUE,
    getJointPrecision = TRUE,
    getReportCovariance = TRUE,
    X1_formula = ~ cpe,
    X2_formula = ~ cpe,
    X1config_cp = as.matrix(2),
    X2config_cp = as.matrix(2),
    covariate_data = covariate_data,
    working_dir = paste0(here("doc", "appendix-VAST-pg"), "/")
  )
  tictoc::toc()
  saveRDS(fit, file = f)
} else {
  fit <- readRDS(f)
}
```

We can look at parameter estimates and their standard errors. First we see estimates from the binomial component and second we see estimates from the positive Gamma component.

```{r check-parameters, echo = TRUE}
fit$parameter_estimates$SD
```

Now we fit the same model in sdmTMB:

```{r sdmTMB-example, echo = TRUE, cache=TRUE}
dat <- dat_ll %>% 
  rename(X = lon, Y = lat)
  
coordinates(dat) <- ~ X + Y
proj4string(dat) <- CRS("+proj=longlat +datum=WGS84")
dat <- as.data.frame(spTransform(dat, CRS("+proj=utm +zone=3")))
# scale to km so values don't get too large
dat$X <- dat$X / 1000 
dat$Y <- dat$Y / 1000

# make mesh and fit model
mesh <- make_mesh(dat, xy_cols = c("X", "Y"),
                  type = "kmeans", n_knots = 750) # or for exact mesh as VAST mesh = fit$spatial_list$MeshList$isotropic_mesh

tictoc::tic()
fit_sdmTMB <- sdmTMB( 
  cpue_kg_km2 ~ 0 + as.factor(year) + cpe,
  spatial_varying = ~ 0 + cpe,
  data = dat, 
  mesh = mesh,
  family = delta_poisson_link_gamma(),
  time = "year", 
  spatial = "on",
  spatiotemporal = "ar1",
  extra_time = c(2020),
  silent = FALSE,
  control = sdmTMBcontrol(newton_loops = 1)
)
tictoc::toc()
fit_sdmTMB
```

```{r compare-vast-sdmTMB1, echo = FALSE}
plot_betas <- function(vast_model, sdmTMB_model, vast_par = "beta1_ft", sdmTMB_pars = 1) {
  s <- vast_model$parameter_estimates$SD
  vast_est1 <- as.list(s, "Estimate", report = FALSE)
  vast_est2 <- as.list(s, "Estimate", report = TRUE)
  vast_sd1 <- as.list(s, "Std. Error", report = FALSE)
  vast_sd2 <- as.list(s, "Std. Error", report = TRUE)
  sdmTMB_est <- as.list(sdmTMB_model$sd_report, "Estimate", report = FALSE)
  sdmTMB_sd <- as.list(sdmTMB_model$sd_report, "Std. Error", report = FALSE)
  b_year_vast <- vast_est1[[vast_par]][!is.na(vast_sd1[[vast_par]])]
  b_year_vast_se <- vast_sd1[[vast_par]][!is.na(vast_sd1[[vast_par]])]
  years <- sort(unique(dat$year))
  lwr_vast <- b_year_vast - 2 * b_year_vast_se
  upr_vast <- b_year_vast + 2 * b_year_vast_se
  plot(years, b_year_vast, ylim = range(c(lwr_vast, upr_vast)))
  segments(years, lwr_vast, years, upr_vast)
  years <- years + 0.05
  if (sdmTMB_pars == 1) {
    points(years, sdmTMB_est$b_j)
    segments(years, sdmTMB_est$b_j - 2 * sdmTMB_sd$b_j, 
    years, sdmTMB_est$b_j + 2 * sdmTMB_sd$b_j,
    col = "red")
  } else {
    points(years, sdmTMB_est$b_j2)
       segments(years, sdmTMB_est$b_j2 - 2 * sdmTMB_sd$b_j2, 
    years, sdmTMB_est$b_j2 + 2 * sdmTMB_sd$b_j2,
    col = "red")
  }
  legend("topright", legend = c("VAST", "sdmTMB"), 
    col = c("black", "red"), bty = "n", lty = c(1, 1))
}
```

We wrote some custom code to extract comparable parameters (not shown above). Here are the annual mean estimates in link space with 95% confidence intervals for the two components to the delta model:

```{r compare-vast-sdmTMB2, echo = TRUE}
par(mfrow = c(2, 1), cex = 0.8, mar = c(1.5, 1, 1, 1), oma = c(2, 3, 1, 1))
plot_betas(fit, fit_sdmTMB, "beta1_ft", sdmTMB_pars = 1)
plot_betas(fit, fit_sdmTMB, "beta2_ft", sdmTMB_pars = 2)
```

While making custom plots of individual elements would require considerable additional code to extract and reformat the necessary components of each output, VAST has a wrapper function that generates the typical plots one may want. Here we stick with the default set of plots (`plot_set = 3`); however, one can specify different standard plots to make by changing the setting of this argument (see `?FishStatsUtils::plot_maps` and `?FishStatsUtils::plot_results`).

```{r save-plots, echo = TRUE, warning = FALSE, cache=TRUE}
plot(
  fit,
  check_residuals = FALSE,
  working_dir = paste0(here("doc", "appendix-VAST-pg"), "/")
)
```

Here we will read in some key plots. We can start by looking at the location of samples and knots.

```{r plot-knots, echo = TRUE, out.width="6in"}
knitr::include_graphics(here("doc", "appendix-VAST-pg", "Data_and_knots.png"))
```

Then we can look at maps of the predicted population densities (here on the log scale).

```{r plot-density, echo = TRUE, out.width="6in"}
knitr::include_graphics(here("doc", "appendix-VAST-pg", "ln_density-predicted.png"))
```

And finally the biomass index.

```{r plot-index, echo = TRUE, out.width="3in"}
if (file.exists(here("doc", "appendix-VAST-pg", "Index-Biomass.png"))) {
  knitr::include_graphics(here("doc", "appendix-VAST-pg", "Index-Biomass.png"))
}
if (file.exists(here("doc", "appendix-VAST-pg", "Index.png"))) {
  knitr::include_graphics(here("doc", "appendix-VAST-pg", "Index.png"))
}
```

We can compare the index we would get using sdmTMB. 

```{r sdmTMB-index, cache=TRUE, echo=TRUE}
# prep prediction grids (all, EBS, NBS) and transform to UTM projection
load(here("extrapolation_grids", "eastern_bering_sea_grid.rda"))
load(here("extrapolation_grids", "northern_bering_sea_grid.rda"))

# EBS grid
grid_ll_ebs <- as.data.frame(eastern_bering_sea_grid)
names(grid_ll_ebs) <- tolower(names(grid_ll_ebs))
grid_ll_ebs <- grid_ll_ebs %>% 
  rename(X = lon, Y = lat)
coordinates(grid_ll_ebs) <- ~ X + Y
proj4string(grid_ll_ebs) <- CRS("+proj=longlat +datum=WGS84")
grid_ebs <- as.data.frame(spTransform(grid_ll_ebs, CRS("+proj=utm +zone=3")))
# or with sf:
# grid_ll <- sf::st_as_sf(
#   x = grid_ll_ebs,
#   coords = c("lon", "lat"),
#   crs = "+proj=longlat +datum=WGS84"
# )
# grid_ll_ebs <- sf::st_transform(grid_ll_ebs, crs = "+proj=utm +zone=3")
grid_ebs$X <- grid_ebs$X / 1000 # scale to km to work with smaller numbers
grid_ebs$Y <- grid_ebs$Y / 1000 

# NBS grid
grid_ll_nbs <- as.data.frame(northern_bering_sea_grid)
names(grid_ll_nbs) <- tolower(names(grid_ll_nbs))
grid_ll_nbs <- grid_ll_nbs %>% 
  rename(X = lon, Y = lat)
coordinates(grid_ll_nbs) <- ~ X + Y
proj4string(grid_ll_nbs) <- CRS("+proj=longlat +datum=WGS84")
grid_nbs <- as.data.frame(spTransform(grid_ll_nbs, CRS("+proj=utm +zone=3")))
grid_nbs$X <- grid_nbs$X / 1000 # scale to km to work with smaller numbers
grid_nbs$Y <- grid_nbs$Y / 1000 

# combined grid
grid <- rbind(grid_ebs, grid_nbs)

# replicate extrapolation grids for each year in data
pred_grid_ebs <- replicate(grid_ebs, "year", unique(dat$year))
pred_grid_nbs <- replicate(grid_nbs, "year", unique(dat$year))
pred_grid <- replicate(grid, "year", unique(dat$year))

# get index for total area, and the two subareas of interest (EBS, NBS)
tictoc::tic()
p <- predict(fit_sdmTMB, newdata = pred_grid, return_tmb_object = TRUE)
ind <- get_index(p, bias_correct = TRUE, area = grid$Area_in_survey_km2)
tictoc::toc()

p_ebs <- predict(fit_sdmTMB, newdata = pred_grid_ebs, return_tmb_object = TRUE)
ind_ebs <- get_index(p_ebs, bias_correct = TRUE, area = grid_ebs$Area_in_survey_km2)

p_nbs <- predict(fit_sdmTMB, newdata = pred_grid_nbs, return_tmb_object = TRUE)
ind_nbs <- get_index(p_nbs, bias_correct = TRUE, area = grid_nbs$Area_in_survey_km2)
```

Now, we can compare the indices. 
<!-- We will read in the VAST index from the `Index.csv` file created by the `plot.fit_model()` method above. -->

```{r index-compare, message=FALSE, warning=FALSE}
library(dplyr)
library(ggplot2)
vast_i <- read.csv(here("doc/appendix-VAST-pg/Index.csv")) %>%
  mutate(index = "VAST", year = as.numeric(Time), est = Estimate, 
    se = Std..Error.for.ln.Estimate.) %>% 
  select(index, year, est, se) %>% 
  mutate(lwr = exp(log(est) + qnorm(0.025) * se)) %>% 
  mutate(upr = exp(log(est) + qnorm(0.975) * se))
sdm_i <- ind %>% mutate(index = "sdmTMB")
both_i <- bind_rows(sdm_i, vast_i) %>% filter(est > 0)
ggplot(both_i, aes(x = year, y = est, ymin = lwr, ymax = upr, colour = index)) + 
  geom_ribbon(alpha = 0.1) +
  geom_line(alpha = 0.8) + 
  ylim(0, max(both_i$upr)) +
  coord_cartesian(expand = FALSE)
```

```{r}
plot(ind$est, vast_i$est[vast_i$est != 0]);abline(0, 1)
plot(ind$upr, vast_i$upr[vast_i$est != 0]);abline(0, 1)
plot(ind$lwr, vast_i$lwr[vast_i$est != 0]);abline(0, 1)

(ind$est - vast_i$est[vast_i$est != 0]) / vast_i$est[vast_i$est != 0]
(ind$upr - vast_i$upr[vast_i$est != 0]) / vast_i$upr[vast_i$est != 0]
(ind$lwr - vast_i$lwr[vast_i$est != 0]) / vast_i$lwr[vast_i$est != 0]
```

This document was built using:

```{r, echo=TRUE}
R.Version()$version.string
packageVersion("VAST")
packageVersion("FishStatsUtils")
```
